---
title: Mapping between Embeddings
params:
  qsize: 500
---

_Goal_: Map mass-spec measurements to plausible spatial expression patterns, based
on MIBI-ToF measurements, and provide some sense of uncertainty in the estimate.

_Outline_:

* For MIBI data, derive cell-level embeddings, based both on the cells' antigen
  expression levels and local spatial ecosystem.
    - This is the part of the analysis that is the most open-ended -- there are
    many ways to build embeddings from either quantitative matrices or images /
    graphs, and we also have to decide how to combine them.
    - We'll start with something simple: U-Map on quantitative and derived
      spatial features, with a parameter trading off the relative weights of the
      two tables.
    - Would be very interesting to try image (autoencoder) or graph (graph nn)
      features.
* Summarize MIBI samples based on these cell-level features. The idea is to
  cluster the embeddings and summarize a sample based on the fraction of cells
  that belong to each cluster.
* Relate mass-spec and MIBI measurements by learning a mapping from common
  features (9 shared antigens and overlapping patient characteristics) to the
  location on the embedding.
  - Our predicted spatial expression for a cytof sample is the spatial
    expression pattern associated with that region in the predicted embedding
    space.
  - We can gauge our ability to actually perform spatial expression imputation
    by (1) our prediction ability, from test mibitof samples to their true
    embeddings, and (2) a proportion-of-variance like quantity on the
    original embeddings[^1].

_Themes_:
* Try assembling easily re-usable components, and understanding their behavior
  when combined. This seems more broadly useful than trying to come up with a
  single model that cannot be reused elsewhere.
* The notion of a "sampling unit" is hierarchical (at least, it's not clear
  cut). We need to think of sampling and variation at both the patient and
  cellular level.
* The dichotomy between ML and stats is artificial, especially in applications
  like this, which are heavy in both non-tabular data and scientific questions.
  Liberally use methods from both disciplines.

```{r}
library("ggplot2")
library("dplyr")
library("reshape2")
library("tibble")
library("forcats")
library("raster")
library("tidyr")
library("stringr")
theme_set(theme_bw() + theme(panel.grid=element_blank()))
```

Loading data...

```{r}
data_dir <- file.path("..", "Data")
load(file.path(data_dir, "mibiSCE.rda"))
tiff_paths <- list.files(file.path(data_dir, "TNBC_shareCellData"), "*.tiff", full=T)
sample_names <- str_extract(tiff_paths, "[0-9]+")

summary(mibi.sce)
glimpse(colData(mibi.sce))
```

Now, we'll start implementing the outline proposed above, using simplest
components that we can find. We'll improve the parts that seem especially weak
in the second pass.

Also for the sake of simplicity, we'll work on subsamples of cells. We won't
randomly sample though, since that would lose interesting spatial variation --
instead we'll extract small quadrants from the full images.

# Subsampling

We'll loop over all the tiffs and extract the `r param$qsize` $\times$
`r params$qsize` top left quadrant from each image.

```{r}
ims <- list()
for (i in seq_along(tiff_paths)) {
  print(paste0(i, "/", length(tiff_paths)))
  r <- raster(tiff_paths[[i]])
  ims[[i]] <- crop(r, extent(1, params$qsize, 1, params$qsize))
}

# just a peek
for (i in sample(seq_along(ims), 10)) {
  plot(ims[[i]])
}

names(ims) <- sample_names
cur_cells <- sapply(ims, raster::unique) %>%
  melt() %>%
  dplyr::rename(cellLabelInImage = "value", SampleID = "L1") %>%
  unite(sample_by_cell, SampleID, cellLabelInImage, remove=F)

colData(mibi.sce)$sample_by_cell <- colData(mibi.sce) %>%
                  as.data.frame() %>%
                  dplyr::select(SampleID, cellLabelInImage) %>%
                  unite(sample_by_cell, SampleID, cellLabelInImage) %>%
                  .[["sample_by_cell"]]

mibi.sce <- mibi.sce[, colData(mibi.sce)$sample_by_cell %in% cur_cells$sample_by_cell]
```

# Embeddings

Now, let's extract some features on which to perform the joint embedding. We'll
transform and reweight the columns, to make the two sets of features more
comparable. First, for transformation, we'll convert antigen expression values
to ranks and then threshold.

```{r}
x <- t(assay(mibi.sce))
for (j in seq_len(ncol(x))) {
  x[, j] <- pmin(rank(x[, j], ties = "random"), params$max_rank) / params$max_rank
}
```

* get features from process segmentations
* center and standardize all
* run u-map after reweighting


# Cells $\to$ Samples


# Guessing the Embedding

[^1]: We can try predicting different sample characteristics from the
    embeddings, for example. It seems like what people do by eye anyways (trying
    to tell whether known group separate).
